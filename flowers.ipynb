{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Import Dependencies"
      ],
      "metadata": {
        "id": "PRbrnwAC0Um8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kiiPw3dSCDIC"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data\n",
        "\n",
        "Data linked in README."
      ],
      "metadata": {
        "id": "7o7R-_NH3qWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract files\n",
        "zip_file_path = '/content/stat-486-image-classification.zip'\n",
        "extract_to_directory = '/content/'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to_directory)\n",
        "\n",
        "# Load labels\n",
        "labels = pd.read_csv('training_labels.csv')\n",
        "images_dir = 'training/training'\n",
        "\n",
        "# Add the directory to the filename ID for full path\n",
        "labels['ID'] = labels['ID'].apply(lambda x: os.path.join(images_dir, x))"
      ],
      "metadata": {
        "id": "urpfj7NI0Pbk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Generators\n",
        "\n",
        "First, I created an image data generator that randomly modifies images through various ways like rescaling, rotation, and magnification to diversify the limited training data available.\n",
        "\n",
        "The training and validation generators then ensure memory efficient training by loading the images into batches and applying the data augments."
      ],
      "metadata": {
        "id": "aLRPqoiZ4w28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the ImageDataGenerator with a validation split and image modification\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.25,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    fill_mode='nearest')\n",
        "\n",
        "# Create the training and validation generators\n",
        "train_generator = datagen.flow_from_dataframe(\n",
        "    dataframe=labels,\n",
        "    directory=None,\n",
        "    x_col='ID',\n",
        "    y_col='target',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow_from_dataframe(\n",
        "    dataframe=labels,\n",
        "    directory=None,\n",
        "    x_col='ID',\n",
        "    y_col='target',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")"
      ],
      "metadata": {
        "id": "aMBOWv3D4vxz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eb20c37-3221-452b-fd20-18c68ca3175b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2591 validated image filenames belonging to 5 classes.\n",
            "Found 863 validated image filenames belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining the Model\n",
        "\n",
        "The input data passes through a sequence of layers. First, they pass through 5 concolutional layers, with each doubling in the number of 3x3 filters and using the ReLU activation function. These layers utilize `BatchNormalization` to scale the inputs of each batch to have a mean of 0 and a variance of 1. They also utilize 2x2 `MaxPooling2D` windows to reduce input dimensionality while preserving the most prominent features.\n",
        "\n",
        "After passing through the convolutional layers, the input is flattened to one dimension before passing through the one-dimensional dense layer with all 512 neurons connected to the neurons of the flattened layer. This provides a comprehensive and dimension-reduced summary of the input. 50% of these neurons are set to 0 to prevent overfitting.\n",
        "\n",
        "The results are passed to a final dense layer with 5 neurons equal to the number of flower types in the data set. The `softmax` activation function produces a multi-class probability distribution.\n",
        "\n",
        "The model is compile with the `categorical_crossentropy` loss function and `Adam` optimizer.\n",
        "\n",
        "During training, the validation loss is monitored. If loss does not improve after 5 epochs, the learning rate is reduced. If loss does not improve after 10 epochs, the previous best weights are restored and training is stopped."
      ],
      "metadata": {
        "id": "7X0x--4896XC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4HBvsETIR6z",
        "outputId": "6ef9099c-381c-44cd-94ab-7ede02ff0670"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ],
      "source": [
        "# Model definition\n",
        "model = Sequential([\n",
        "    # Convolutional layer 1\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    # Convolutional layer 2\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    # Convolutional layer 3\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    # Convolutional layer 4\n",
        "    Conv2D(256, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    # Convolutional layer 5\n",
        "    Conv2D(512, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    # Flatten the results to feed into a DNN\n",
        "    Flatten(),\n",
        "\n",
        "    # 512 neuron hidden layer\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    # Output layer\n",
        "    Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Callbacks for early stopping and learning rate reduction\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Fit\n",
        "\n",
        "I trained this model for 100 epochs."
      ],
      "metadata": {
        "id": "v1PjZfCRRl9V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hfyq2ql9IUMH",
        "outputId": "5678794c-e20e-4384-dd8d-7ebb9286c884"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "81/81 [==============================] - 612s 8s/step - loss: 0.3885 - accuracy: 0.8599 - val_loss: 0.6116 - val_accuracy: 0.8100 - lr: 2.0000e-04\n",
            "Epoch 2/25\n",
            "81/81 [==============================] - 603s 7s/step - loss: 0.3779 - accuracy: 0.8695 - val_loss: 0.6473 - val_accuracy: 0.8053 - lr: 2.0000e-04\n",
            "Epoch 3/25\n",
            "81/81 [==============================] - 600s 7s/step - loss: 0.3773 - accuracy: 0.8634 - val_loss: 0.5964 - val_accuracy: 0.8019 - lr: 2.0000e-04\n",
            "Epoch 4/25\n",
            "81/81 [==============================] - 602s 7s/step - loss: 0.3768 - accuracy: 0.8723 - val_loss: 0.5806 - val_accuracy: 0.8053 - lr: 2.0000e-04\n",
            "Epoch 5/25\n",
            "81/81 [==============================] - 623s 8s/step - loss: 0.3243 - accuracy: 0.8788 - val_loss: 0.5596 - val_accuracy: 0.8076 - lr: 2.0000e-04\n",
            "Epoch 6/25\n",
            "81/81 [==============================] - 604s 7s/step - loss: 0.3576 - accuracy: 0.8780 - val_loss: 0.6709 - val_accuracy: 0.7984 - lr: 2.0000e-04\n",
            "Epoch 7/25\n",
            "81/81 [==============================] - 603s 7s/step - loss: 0.3578 - accuracy: 0.8734 - val_loss: 0.6100 - val_accuracy: 0.7949 - lr: 2.0000e-04\n",
            "Epoch 8/25\n",
            "81/81 [==============================] - 610s 8s/step - loss: 0.3222 - accuracy: 0.8796 - val_loss: 0.5265 - val_accuracy: 0.8239 - lr: 2.0000e-04\n",
            "Epoch 9/25\n",
            "81/81 [==============================] - 616s 8s/step - loss: 0.3494 - accuracy: 0.8707 - val_loss: 0.5713 - val_accuracy: 0.8169 - lr: 2.0000e-04\n",
            "Epoch 10/25\n",
            "81/81 [==============================] - 599s 7s/step - loss: 0.3363 - accuracy: 0.8780 - val_loss: 0.6997 - val_accuracy: 0.7879 - lr: 2.0000e-04\n",
            "Epoch 11/25\n",
            "81/81 [==============================] - 598s 7s/step - loss: 0.3146 - accuracy: 0.8823 - val_loss: 0.6186 - val_accuracy: 0.7937 - lr: 2.0000e-04\n",
            "Epoch 12/25\n",
            "81/81 [==============================] - 599s 7s/step - loss: 0.3211 - accuracy: 0.8846 - val_loss: 0.6521 - val_accuracy: 0.8111 - lr: 2.0000e-04\n",
            "Epoch 13/25\n",
            "81/81 [==============================] - 596s 7s/step - loss: 0.3175 - accuracy: 0.8881 - val_loss: 0.6013 - val_accuracy: 0.8076 - lr: 2.0000e-04\n",
            "Epoch 14/25\n",
            "81/81 [==============================] - 594s 7s/step - loss: 0.2796 - accuracy: 0.8966 - val_loss: 0.5445 - val_accuracy: 0.8273 - lr: 4.0000e-05\n",
            "Epoch 15/25\n",
            "81/81 [==============================] - 585s 7s/step - loss: 0.2761 - accuracy: 0.9012 - val_loss: 0.5593 - val_accuracy: 0.8204 - lr: 4.0000e-05\n",
            "Epoch 16/25\n",
            "81/81 [==============================] - 586s 7s/step - loss: 0.2537 - accuracy: 0.9070 - val_loss: 0.5285 - val_accuracy: 0.8250 - lr: 4.0000e-05\n",
            "Epoch 17/25\n",
            "81/81 [==============================] - 591s 7s/step - loss: 0.2652 - accuracy: 0.9074 - val_loss: 0.5732 - val_accuracy: 0.8100 - lr: 4.0000e-05\n",
            "Epoch 18/25\n",
            "81/81 [==============================] - 590s 7s/step - loss: 0.2553 - accuracy: 0.9062 - val_loss: 0.5261 - val_accuracy: 0.8227 - lr: 4.0000e-05\n",
            "Epoch 19/25\n",
            "81/81 [==============================] - 589s 7s/step - loss: 0.2450 - accuracy: 0.9070 - val_loss: 0.5316 - val_accuracy: 0.8343 - lr: 4.0000e-05\n",
            "Epoch 20/25\n",
            "81/81 [==============================] - 620s 8s/step - loss: 0.2483 - accuracy: 0.9120 - val_loss: 0.5796 - val_accuracy: 0.8262 - lr: 4.0000e-05\n",
            "Epoch 21/25\n",
            "81/81 [==============================] - 594s 7s/step - loss: 0.2389 - accuracy: 0.9101 - val_loss: 0.5652 - val_accuracy: 0.8308 - lr: 4.0000e-05\n",
            "Epoch 22/25\n",
            "81/81 [==============================] - 590s 7s/step - loss: 0.2343 - accuracy: 0.9097 - val_loss: 0.5653 - val_accuracy: 0.8297 - lr: 4.0000e-05\n",
            "Epoch 23/25\n",
            "81/81 [==============================] - 614s 8s/step - loss: 0.2471 - accuracy: 0.9101 - val_loss: 0.5735 - val_accuracy: 0.8076 - lr: 4.0000e-05\n",
            "Epoch 24/25\n",
            "81/81 [==============================] - 614s 8s/step - loss: 0.2346 - accuracy: 0.9147 - val_loss: 0.5506 - val_accuracy: 0.8262 - lr: 1.0000e-05\n",
            "Epoch 25/25\n",
            "81/81 [==============================] - 606s 7s/step - loss: 0.2280 - accuracy: 0.9213 - val_loss: 0.5889 - val_accuracy: 0.8250 - lr: 1.0000e-05\n"
          ]
        }
      ],
      "source": [
        "# Fit model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=25,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping, reduce_lr]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save and Load Model\n",
        "\n",
        "Model can be saved and reloaded to train over multiple days, as your free daily TPU/GPU usage on Google Colab is limited."
      ],
      "metadata": {
        "id": "2v_Qhwce-rBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "model.save('flower_classification.h5')"
      ],
      "metadata": {
        "id": "brK_bHHe5axn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model\n",
        "model = load_model('flower_classification_model.h5')"
      ],
      "metadata": {
        "id": "O9jL5vS0Q_DZ"
      },
      "execution_count": 7,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}